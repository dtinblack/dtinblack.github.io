---
layout: post
title: Will Big Data Ever Be Thickened?
description: "A development challenge for Big Data."
modified: 2016-01-26
tags: [Big Data, ethnography, Thick Data]
---

<a href="https://en.wikipedia.org/wiki/Big_data" >Big Data </a> is the big news. Many businesses, universities and other organisations are investing large amounts of money into developing technology that exploits the many pieces of data that
we generate from our lives. In amongst the marketing frenzy for Big Data I came across  
the term
<a href="https://www.brandwatch.com/2014/04/what-is-thick-data-and-why-should-you-use-it/">
Thick Data </a> which has been coined to cover a deeper look at the context within which data is gathered.  I was intrigued and imagined a big pot of data stew being stirred with a thickening agent !

Trying to find an agreed definition for Thick Data has proved impossible. However summing and averaging the various definitions found on the web, I arrived at: Thick Data is data gathered about our behavior and underlying motivations. Traditionally the data has been gathered through surveys, questionnaires,
focus groups, interviews, journals, videos and so on and gathered and interpreted by analysed by ethnographers ( the study of people and cultures and how they change ) and anthropologists ( the study of various aspects of humans within past and present societies ). Compared to the people who collect and analyse Big Data ( they often sit in IT functions with analytical degrees), there is a large gap between the two groups.

How could Big Data be thickened ? What capability would computer technology have to achieve
to add context to data ?

In Clifford Geertz’ paper
<a href="https://philpapers.org/archive/GEETTD.pdf" >
Thick Description: Toward an Interpretive Theory of Culture</a>
he describes a situation challenge that computer technology would have to overcome to thicken data ( if you are interested in anthropology and ethnography then the whole paper is worth reading ):
“… two boys rapidly contracting the eyelids of their right eyelids of their eyes. In one,
this is an involuntary twitch, the other a conspiratorial signal to a friend. The two movements
are, as movements, identical, from an I-am-a-camera, “phenomomenalistic” observation of them alone, one could not tell which was twitch and which was wink. Yet the difference, however
unphotographicable, between twitch and a wink is vast, as anyone unfortunate enough to have had
the first taken for the second knows. The winker is communicating, and indeed in a precise way:
(1) deliberately, (2) to someone in particular, (3) impart a particular message, (4) according
to socially established code, and (5) without of the cognizance of the rest of the company.”  

Current computer technology can capture and analysis eye movement, and possibly distinguish a wink from normal eyelid movement, but can not interpret the communication of a wink. Also, computer technology has developed to a point where emotions
can be captured ( see the
<a href="https://www.myfeel.co/">Feel Wrist Band</a> ) and levels of motivation
can be measured ( usually measured against set goals ). However, gathering data to analyse the social context, as described in the passage above, has a long way to go.

The challenge for both computer technologists, and sociologists is: what developments in computer technology are required to gather thick data to enable a greater insight into our behaviours and motivations?

<i>Since writing this post I came across an interesting TED talk -
<a href="https://www.ted.com/talks/tricia_wang_the_human_insights_missing_from_big_data/transcript?utm_campaign=Data%2BElixir&utm_medium=email&utm_source=Data_Elixir_143">The human insights missing from big data</a> - given by <a href="">Tricia Wang</a> who discusses the advantages of using 'thick data'.  
